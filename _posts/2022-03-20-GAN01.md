# GAN炼丹师blog01

### 前言

为了当一个有水平的炼丹师，从今天起决定把每次的炼丹过程给记录下来，毕竟炼丹一部分靠知识储备，再有一部分就是靠经验了



## 经验

1.今天弄明白了如何用keras实现将G和D连接起来训练G的时候，将**D的参数进行锁住**，在返回完整GAN网络（G与D连接起来）时，将GAN中的D模型的trainable参数设置为false，然后在GAN模型构造函数外对GAN进行compile（有博客说不这样的话任何地方的D模型的trainable参数都是false），这样的话只有在GAN中的D的trainable才是false，其余地方都是true

2.再一个就是昨天看过李宏毅介绍GAN时，讲到训练D的时候多训练几轮，然后训练一次G（一个就够了），这样效果会好，我在这样进行之后效果确实好很多，一开始G的loss就降的很快，但是1w5次epoch之后loss就很难下降了。

于是我决定当D的准确率小于60的时候，我才让D每回多训练两次，结果是2每当D的acc小于60后，下一次D的acc都会突增到70多，然后再迭代几次又掉下60，又重复上面的过程，这样迭代3w次，效果不如上面直接每次都先训练3次D（不知道是训练次数少的原因---毕竟这样做迭代3w次的话平均每一个epoch就少训练了至少1.5次D，还是说我这种想法的问题）

下面是每次都训练3次D然后训练一个G的生成图片构成的动图:

![avator](../images/training.gif)

下面则是我设置之后的训练gif：

![avator](../images/new_training.gif)